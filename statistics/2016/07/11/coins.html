<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Coins</title>
  <meta name="description" content="In this post I illustrate the logic behind binomial probability distributions and how this logic applies when large numbers of samples are obtained.">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://kuruga.github.io//statistics/2016/07/11/coins.html">
  <link rel="alternate" type="application/rss+xml" title="Satisfying Constraints" href="https://kuruga.github.io//feed.xml">
</head>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Satisfying Constraints</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Coins</h1>
    <p class="post-meta"><time datetime="2016-07-11T22:00:00+09:00" itemprop="datePublished">Jul 11, 2016</time> • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Matti</span></span></p>
  </header>

  
    <script type="text/javascript"
        src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  

  <div class="post-content" itemprop="articleBody">
    <p>In this post I illustrate the logic behind binomial probability distributions and how this logic applies when large numbers of samples are obtained.</p>

<h2 id="content">Content</h2>

<ul>
  <li><a href="#CoinFlipping">Decisions from Uncertainty</a>
    <ul>
      <li><a href="#LargeNumbers">Large Numbers</a></li>
    </ul>
  </li>
  <li><a href="#BinomialExperiments">Binomial Experiments</a></li>
  <li><a href="#possibilitiesProbabilities">From Possibilities to Probabilities</a>
    <ul>
      <li><a href="#pascalTriangle">The Pascal Triangle</a></li>
      <li><a href="#BinomialCoefficient">The Binomial Coefficient</a></li>
      <li><a href="#BiasedBinomial">Biased Binomial Distributions</a></li>
    </ul>
  </li>
</ul>

<p><a name="CoinFlipping"></a></p>

<h2 id="decisions-from-uncertainty">Decisions from Uncertainty</h2>

<p>A decision between two exclusive options can become difficult when we have no apparent reason or authority to choose one over the other. <br />
A common way to resolve such a dilemma is to flip a coin and assign one choice to each side of it. If the coin should land showing heads, one option is chosen and if it should land tails, the other option wins.</p>

<p>Money is often associated with power but the reason for occasionally allowing a single coin to decide about our fate has little to do with its monetary value.
The actual reason for throwing a coin is the <strong>uncertainty</strong> that we have about what side the coin will land on. <br />
Our basic sensory and predictive abilities are just too limited to even try to correctly estimate the outcome of a coin toss from initial conditions and forces acting on the coin. Instead we say that the outcome of a coin toss is random and call the underdetermined process of coin flipping a <strong>random variable</strong>.</p>

<p>A perfectly balanced coin maximizes the uncertainty about the outcome of a coin toss because it is equally likely to land on either of two sides. 
But how do we know that a coin is perfectly balanced? <br />
One answer is to <strong>learn from data</strong>.</p>

<p>This means that we evaluate the outcome of actual coin tosses to infer how well the coin is balanced. <br />
A balanced coin should be <em>fair</em> in the sense that it should land on each side approximately half of the time.</p>

<p>In <em>R</em> there are multiple ways to simulate tossing coins. 
In the following example I use the inbuilt <code class="highlighter-rouge">sample()</code> function as the main component of a <code class="highlighter-rouge">FairCoinToss()</code> function.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">FairCoinToss</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="c1"># Simulates n fair coin tosses.
</span><span class="w">  </span><span class="c1">#
</span><span class="w">  </span><span class="c1"># Args:
</span><span class="w">  </span><span class="c1">#  n: number of coin tosses
</span><span class="w">  </span><span class="c1">#  
</span><span class="w">  </span><span class="c1"># Returns:
</span><span class="w">  </span><span class="c1">#  The output of n fair coin tosses (vector of 1s and 0s)
</span><span class="w">
  </span><span class="n">possibleOutcomes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">)</span><span class="w">  </span><span class="c1"># 1 = heads, 0 = tails
</span><span class="w">  </span><span class="n">probabilities</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="c1"># probabilities of outcomes
</span><span class="w">  
  </span><span class="c1"># use the inbuilt sample function to pick n samples with replacement
</span><span class="w">  </span><span class="c1"># from a list of possible outcomes according to predefined
</span><span class="w">  </span><span class="c1"># probabilities for choosing each possible outcome
</span><span class="w">  </span><span class="c1"># This simulates n random coin flips
</span><span class="w">  </span><span class="n">side</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">possibleOutcomes</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> 
                 </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">probabilities</span><span class="p">)</span><span class="w">
  </span><span class="nf">return</span><span class="p">(</span><span class="n">side</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1"># simulate a few coin flips
</span><span class="n">FairCoinToss</span><span class="p">()</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>## [1] 1
</code></pre>
</div>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">FairCoinToss</span><span class="p">()</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>## [1] 1
</code></pre>
</div>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">FairCoinToss</span><span class="p">()</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>## [1] 0
</code></pre>
</div>

<p>Conveniently the sample function allows drawing of multiple samples in one step. In the above <code class="highlighter-rouge">FairCoinToss()</code> function this functionality is preserved so that we can flip as many coins as we like with one function call in which the argument <code class="highlighter-rouge">n</code> is the number of coin tosses.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">FairCoinToss</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">)</span><span class="w"> </span><span class="c1"># 10 fair coin tosses
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##  [1] 1 1 1 0 1 0 1 1 0 0
</code></pre>
</div>

<p>In the case of this simulated <code class="highlighter-rouge">FairCoinToss()</code> we already know that it is fair (assuming we trust <em>R</em>’s <code class="highlighter-rouge">sample()</code> function) because the probability of each side is defined to be 0.5.</p>

<p>However, random variables can have different probabilities associated with their possible outcomes.
Let’s for instance assume we have a function <code class="highlighter-rouge">GoldCoinToss()</code> which simulates an old gold coin for which we don’t know the probabilities. We imagine that this old coin isn’t as symmetric as modern coins and assume that it is a bit heavier on one side than on the other. Intuitively this should make it more likely to land on its heavy side.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="c1"># Attention: This code won't actually execute without given probabilities
</span><span class="n">GoldCoinToss</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="c1"># Simulates n coin tosses with a coin found on the street.
</span><span class="w">  </span><span class="c1">#
</span><span class="w">  </span><span class="c1"># Args:
</span><span class="w">  </span><span class="c1">#  n: number of coin tosses
</span><span class="w">  </span><span class="c1">#  
</span><span class="w">  </span><span class="c1"># Returns:
</span><span class="w">  </span><span class="c1">#  The output of n coin tosses (vector of 1s and 0s)
</span><span class="w">  
  </span><span class="n">possibleOutcomes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">)</span><span class="w">  </span><span class="c1"># 1 = heads, 0 = tails
</span><span class="w">  </span><span class="n">probabilities</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="o">**********</span><span class="w">  </span><span class="c1"># unknown probabilities of outcomes
</span><span class="w">  </span><span class="n">side</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">possibleOutcomes</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> 
                 </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">probabilities</span><span class="p">)</span><span class="w">
  </span><span class="nf">return</span><span class="p">(</span><span class="n">side</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1"># toss the gold coin 10 times
</span><span class="n">GoldCoinToss</span><span class="p">(</span><span class="m">10</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>##  [1] 1 1 1 1 0 0 1 0 1 0
</code></pre>
</div>

<p>We can see that this coin can also land on both sides. But what is the expected ratio of heads and tails?</p>

<p><a name="LargeNumbers"></a></p>

<h3 id="large-numbers">Large Numbers</h3>

<p>To estimate a coin’s balance or fairness we can make use of the so called <strong>law of large numbers</strong> which states that the average result of multiple trials tends to approach the expected value as the number of trials increases. <br />
In the case of the sides of our coins, this means that for a large number of coin flips, the average number of heads and tails should be close to their respective probabilities.</p>

<p>Because we are representing heads and tails with 1 and 0 we can simply obtain the ratio of heads by calcuating the arithmetic mean of a list of outcomes.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="c1"># outcome of 1000 fair coin tosses
</span><span class="n">fairOutcomes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">FairCoinToss</span><span class="p">(</span><span class="m">1000</span><span class="p">)</span><span class="w">
</span><span class="c1"># ratio of 1's in 1000 fair coin tosses
</span><span class="n">mean</span><span class="p">(</span><span class="n">fairOutcomes</span><span class="p">)</span><span class="w"> 
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>## [1] 0.495
</code></pre>
</div>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="c1"># outcome 1000 gold coin tosses
</span><span class="n">goldOutcomes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">GoldCoinToss</span><span class="p">(</span><span class="m">1000</span><span class="p">)</span><span class="w">
</span><span class="c1"># ratio of 1's in 1000 gold coin tosses
</span><span class="n">mean</span><span class="p">(</span><span class="n">goldOutcomes</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>## [1] 0.603
</code></pre>
</div>

<p>The ratio of heads in the case of the fair coin is really close to the actual probability assigned to heads. In the case of the gold coin, heads occurred more often which suggests that the coin could be a bit unbalanced.</p>

<p>But this might still be coincidence. Maybe 1000 coin tosses were not enough to smooth out the randomness of the sampling procedure.</p>

<p>To get a better idea let us have a look at the law of large numbers in action by repeatedly calculating and visualizing averages for growing numbers of coin tosses:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">3000</span><span class="w"> </span><span class="c1"># total number of coin flips
</span><span class="n">means</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">vector</span><span class="p">(</span><span class="s2">"double"</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="c1"># allocate space for storing means
</span><span class="n">coins</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">FairCoinToss</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="c1"># n fair coin flips
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="c1"># calculate mean for growing fractions of coin flips
</span><span class="w">  </span><span class="c1"># and store it in a list of means
</span><span class="w">  </span><span class="n">means</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">coins</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="n">n</span><span class="p">])</span><span class="w"> 
</span><span class="p">}</span><span class="w">

</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="n">n</span><span class="p">),</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">means</span><span class="p">,</span><span class="w"> 
     </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"mean heads vs. number of included coin flips"</span><span class="p">,</span><span class="w">
     </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"#coin flips"</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"mean"</span><span class="p">,</span><span class="w">
     </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"l"</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="o">=</span><span class="m">0.3</span><span class="p">)</span><span class="w"> </span><span class="c1"># show entries as a line
# display actual probability of heads as a red line
</span><span class="n">abline</span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s2">"red"</span><span class="p">)</span><span class="w"> 
</span><span class="n">grid</span><span class="p">()</span><span class="w">
</span></code></pre>
</div>

<p><img src="/media/coins-lawOfLargeNumbers-1.png" alt="plot of chunk lawOfLargeNumbers" /></p>

<p>The figure shows that after 1000 coin tosses the mean is already fairly close to the actual probability and fluctuates only a little. The decrease in fluctuation is due to the fact that individual outcomes lose relative influence on the average as the number of trials increases:</p>

<p>When calculating the mean for a list of values \(x = {x_1, x_2, …, x_n}\), the denominator \(n\) corresponds to the number of trials (coin flips) whereas the numerator is the sum of all outcomes.</p>

<script type="math/tex; mode=display">\bar{x} = \frac{\sum_{1}^{n}x_i}{n}</script>

<p>This can be rewritten as</p>

<script type="math/tex; mode=display">\bar{x} = \sum_{1}^{n}\left(x_i \cdot \frac{1}{n}\right)</script>

<p>In this sum each entry receives a weight of \(\frac{1}{n}\).
Therefore the relative influence of each value shrinks with each new sample which explains the decreasing fluctuation.</p>

<p>But can such observations justificy drawing conclusions about the actual bias/fairness of a coin?</p>

<p><a name="BinomialExperiments"></a></p>

<h2 id="binomial-experiments">Binomial Experiments</h2>

<p>A single coin toss is an experiment with two possible outcomes. This kind of single binary trial is also known as a <strong>Bernoulli experiment</strong>.
Repeated coin tossing, i.e. concatenating multiple Bernoulli experiments, is one instance of a so called <strong>binomial experiment</strong>.</p>

<p>Earlier we observed that the average of a binomial experiment approaches the actual bias of the variable of interest (e.g. the probability of a coin to land showing heads) as the number of trials increases.
However, we still lack a notion of (un-)certainty about such estimates.</p>

<p>Let us have a look at what happens if we calculate the means of multiple independent binomial experiments.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">BinomMeans</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">experiments</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10000</span><span class="p">,</span><span class="w"> </span><span class="n">coinTosses</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="c1"># function to collect the mean outcomes of multiple binomial experiments
</span><span class="w">  </span><span class="c1">#
</span><span class="w">  </span><span class="c1"># Args:
</span><span class="w">  </span><span class="c1">#  experiments: number of experiments
</span><span class="w">  </span><span class="c1">#  coinTosses:  number of trials per experiment
</span><span class="w">  </span><span class="c1">#  p:           proportion of 1s
</span><span class="w">  </span><span class="c1">#
</span><span class="w">  </span><span class="c1"># Returns:
</span><span class="w">  </span><span class="c1">#  means: mean outcomes of multiple binomial experiments
</span><span class="w">  
  </span><span class="n">means</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="kc">NA</span><span class="p">)</span><span class="w">   </span><span class="c1"># make a list to store the mean values
</span><span class="w">  </span><span class="nf">length</span><span class="p">(</span><span class="n">means</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">experiments</span><span class="w"> </span><span class="c1"># allocate memory to store the mean values
</span><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">experiments</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1"># for each experiment
</span><span class="w">    </span><span class="c1"># flip a coin multiple times and store the average number of 
</span><span class="w">    </span><span class="c1"># 1's in a list
</span><span class="w">    </span><span class="n">means</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">sample</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">coinTosses</span><span class="p">,</span><span class="w"> 
                            </span><span class="n">replace</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="m">1</span><span class="o">-</span><span class="n">p</span><span class="p">)))</span><span class="w">
  </span><span class="p">}</span><span class="w">
  </span><span class="nf">return</span><span class="p">(</span><span class="n">means</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
</div>

<p>We make a histograms of 100 means that are all based on 10000 independent fair coin tosses.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="c1"># 1000 means of 10000 coin tosses each
</span><span class="n">means100Exp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">BinomMeans</span><span class="p">(</span><span class="n">experiments</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">coinTosses</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10000</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w">

</span><span class="c1"># show histograms of the collected means
</span><span class="n">hist</span><span class="p">(</span><span class="n">means100Exp</span><span class="p">,</span><span class="w"> </span><span class="n">breaks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">42</span><span class="p">,</span><span class="w"> </span><span class="n">freq</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">v</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">)</span><span class="w"> </span><span class="c1"># draw vertical line at actual bias
</span></code></pre>
</div>

<p><img src="/media/coins-collectedMeans-1.png" alt="plot of chunk collectedMeans" /></p>

<p>The means are scattered around the actual bias but it seems that there is a tendency towards the center.</p>

<p>To have more clarity we make the computer work a little harder: <br />
<strong>10000 means</strong> of <strong>10000 coin tosses</strong> each!</p>

<p><a name="SampledFairBinomial"></a></p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="c1"># 10000 means of 1000 coin tosses each. This may take a few seconds.
</span><span class="n">means10000Exp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">BinomMeans</span><span class="p">(</span><span class="n">experiments</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10000</span><span class="p">,</span><span class="w"> </span><span class="n">coinTosses</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w">

</span><span class="c1"># show histograms of the collected means
</span><span class="n">hist</span><span class="p">(</span><span class="n">means10000Exp</span><span class="p">,</span><span class="w"> </span><span class="n">breaks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">42</span><span class="p">,</span><span class="w"> </span><span class="n">freq</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span><span class="n">abline</span><span class="p">(</span><span class="n">v</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"red"</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<p><img src="/media/coins-moreCollectedMeans-1.png" alt="plot of chunk moreCollectedMeans" /></p>

<p>This distribution no longer looks arbitrary. In fact, it appears to resemble a discrete version of what some of you may remember as the <a href="https://en.wikipedia.org/wiki/Normal_distribution">normal or gaussian distribution</a>.</p>

<p>But why does the distribution of mean values start taking this particular shape as the number of samples increases?</p>

<p><a name="possibilitiesProbabilities"></a></p>

<h2 id="from-possibilities-to-probabilities">From Possibilities to Probabilities</h2>

<p>The above approximate distribution does not only appear after a lot of coin flipping but is actually a property that directly <a href="/statistics/2016/07/11/Probabilities.html">arises from the number of ways</a> in which particular events can occur.</p>

<p>If we flip a fair coin once there are two possible outcomes, heads <code class="highlighter-rouge">h</code> and tails <code class="highlighter-rouge">t</code> with equal <a href="/statistics/2016/07/11/Probabilities.html">probabilities</a> of \(\frac{1}{2}\).</p>

<p>If we flip the coin twice we get one of the three following outcomes: <br />
<code class="highlighter-rouge">hh</code>, <code class="highlighter-rouge">tt</code>, <code class="highlighter-rouge">ht</code>. However, not taking the order into account, there is only one way each for <code class="highlighter-rouge">hh</code> and <code class="highlighter-rouge">tt</code> to occur but there are two ways in which <code class="highlighter-rouge">ht</code> can occur (<code class="highlighter-rouge">ht</code> and <code class="highlighter-rouge">th</code>).</p>

<p>Accordingly, the probabilities of <code class="highlighter-rouge">hh</code> and <code class="highlighter-rouge">tt</code> are only \(\frac{1}{2} \cdot \frac{1}{2} = \frac{1}{4}\) each whereas the probability of <code class="highlighter-rouge">ht</code> is \(2 \cdot \left(\frac{1}{2} \cdot \frac{1}{2}\right) = \frac{1}{2}\).</p>

<p>We can also illustrate this concept in a <em>graph</em> where the number of paths that lead to a node corresponds to the number of possible cases in which a particular distribution of heads and tails can occur.</p>

<p><img src="/media/coins-unnamed-chunk-2-1.png" alt="plot of chunk unnamed-chunk-2" /></p>

<p>This graph represents the possible outcomes of a binomial experiment with two trials. You can think about it as showing the possible outcomes of two subsequent coin flips where “1” stands for one side and “0” for the other side of the coin.</p>

<p>Similarly with three coin flips we have 4 possible outcomes out of which two (<code class="highlighter-rouge">hhh</code> and <code class="highlighter-rouge">ttt</code>) have the probability \(\frac{1}{2} \cdot \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{8}\) and two (<code class="highlighter-rouge">hht</code> and <code class="highlighter-rouge">tth</code>) have the probability \(3 \cdot \left(\frac{1}{2} \cdot \frac{1}{2} \cdot \frac{1}{2}\right) = \frac{3}{8}\).</p>

<p><img src="/media/coins-unnamed-chunk-3-1.png" alt="plot of chunk unnamed-chunk-3" /></p>

<p><a name="pascalTriangle"></a></p>

<h3 id="the-pascal-triangle">The Pascal Triangle</h3>

<p>There is another graphical representation which makes determining the number of possible paths leading to a node even easier.</p>

<p>Take a look at the following graph:</p>

<p><img src="/media/coins-pascal4-1.png" alt="plot of chunk pascal4" /></p>

<p>In this type of graph which is known as <strong>pascal triangle</strong>, each node is labeled with the number of paths that lead to it.
The label of a node is also the sum of the values of the direct parent nodes when the value of the first parent is 1 because the number of paths that lead to a node corresponds to the sum of the number of paths leading to each of its parent nodes.</p>

<p>A transition towards a new node is always assigned to one of two possible outcomes (such as sides of a coin) depending on whether the new node is on the lower left or right of its parent node.
Therefore, by simply following one path leading to a certain node and keeping track how many transitions go left and right one can infer the event which the node represents.</p>

<p>For instance, the first node labeled with a ‘3’ in the above example can only be reached by a combination of two left transitions and one right transition and thus represents the event <code class="highlighter-rouge">(l, l, r)</code>, <code class="highlighter-rouge">(h, h, t)</code>, or <code class="highlighter-rouge">(1, 1, 0)</code>.</p>

<p><a name="BinomialCoefficient"></a></p>

<h3 id="the-binomial-coefficient">The Binomial Coefficient</h3>

<p>The value of a node in the pascal triangle can also be calculated using the formula for the <em>binomial coefficient</em>.</p>

<p>The binomial coefficient is defined as</p>

<script type="math/tex; mode=display">\binom{n}{k} = \frac{n!}{k!(n-k)!}</script>

<p>The notation \(\binom{n}{k}\) does not correspond to a traditional vector but can instead be understood as representing the <em>number of ways to get exactly <code class="highlighter-rouge">k</code> successes (outcomes of one type) in <code class="highlighter-rouge">n</code> independent bernoulli trials</em>.</p>

<p>Translated to the coin example this becomes the number of ways to get <code class="highlighter-rouge">k</code> heads in <code class="highlighter-rouge">n</code> independent coin tosses.</p>

<p>Example: <br />
\(\binom{3}{2} = 3\): There are 3 possible ways in which three coin tosses could produce exactly two heads.</p>

<p><img src="/media/coins-BinomTree05-1.png" alt="plot of chunk BinomTree05" /></p>

<p>To calculate the binomial coefficient in <em>R</em> one can use the function <code class="highlighter-rouge">choose(n, k)</code>.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">choose</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>## [1] 3
</code></pre>
</div>

<p>So how does the size of a binomial experiment influence the distribution of possible paths which realise individual events?</p>

<p>Take a look at individual rows of the following Pascal Triangle:</p>

<p><img src="/media/coins-pascal9-1.png" alt="plot of chunk pascal9" /></p>

<p>Nodes near the center of a row can be reached in many more ways than nodes on the edges.
This means that there are more ways to have a balanced number of left and right transitions than uneven combinations.</p>

<p>Let’s have a look at the histograms for the values in some of these rows.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">BinomHist</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">relative</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="c1"># plot histogram of possible path counts for different success ratios 
</span><span class="w">  </span><span class="c1"># in an unbiased binomial experiment with sample size n
</span><span class="w">  </span><span class="c1">#
</span><span class="w">  </span><span class="c1"># Args:
</span><span class="w">  </span><span class="c1">#  n:        integer, sample size
</span><span class="w">  </span><span class="c1">#  relative: boolean, TRUE for relative path counts, FALSE for absolute
</span><span class="w">  
  </span><span class="c1"># ways to get 0:n successes in n independent bernoulli experiments
</span><span class="w">  </span><span class="n">paths</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">choose</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="o">:</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="c1"># use binomial coefficient for path counting
</span><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">relative</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="n">paths</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">paths</span><span class="o">/</span><span class="p">(</span><span class="m">2</span><span class="o">^</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="c1"># normalize counts if requested
</span><span class="w">  </span><span class="p">}</span><span class="w">
  </span><span class="n">ratios</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="o">:</span><span class="n">n</span><span class="p">)</span><span class="o">/</span><span class="n">n</span><span class="w"> </span><span class="c1"># x-axis shows success ratios
</span><span class="w">  </span><span class="n">barplot</span><span class="p">(</span><span class="n">height</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">paths</span><span class="p">,</span><span class="w"> </span><span class="n">names.arg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ratios</span><span class="p">,</span><span class="w">
          </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">paste</span><span class="p">(</span><span class="s2">"Path distribution of L/R ratios,\n"</span><span class="p">,</span><span class="w">
                       </span><span class="s2">"n = "</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">),</span><span class="w">
          </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"left/right ratio"</span><span class="p">,</span><span class="w"> 
          </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ifelse</span><span class="p">(</span><span class="n">relative</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> 
                        </span><span class="s2">"Relative number of paths"</span><span class="p">,</span><span class="w"> </span><span class="s2">"Number of paths"</span><span class="p">),</span><span class="w">
          </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"lightblue"</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1"># Show histograms for different sample sizes
#par(mfrow = c(2, 2))
</span><span class="n">BinomHist</span><span class="p">(</span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<p><img src="/media/coins-unnamed-chunk-4-1.png" alt="plot of chunk unnamed-chunk-4" /></p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">BinomHist</span><span class="p">(</span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<p><img src="/media/coins-unnamed-chunk-4-2.png" alt="plot of chunk unnamed-chunk-4" /></p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">BinomHist</span><span class="p">(</span><span class="m">30</span><span class="p">,</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w"> </span><span class="c1"># show relative number of paths for large n
</span></code></pre>
</div>

<p><img src="/media/coins-unnamed-chunk-4-3.png" alt="plot of chunk unnamed-chunk-4" /></p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">BinomHist</span><span class="p">(</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<p><img src="/media/coins-unnamed-chunk-4-4.png" alt="plot of chunk unnamed-chunk-4" /></p>

<p><a name="BinomHist100"></a></p>

<p>Does this look familiar?</p>

<p>Each of these histograms represents the distribution of possible paths for different success ratios in a binomial experiment in which <code class="highlighter-rouge">p = 0.5</code>. When the counts are normalized to add up to one, their distribution can be interpreted as the <strong>probability distribution</strong> of the success ratio of <code class="highlighter-rouge">n</code> fair trials (coin flips).</p>

<p>In the <a href="#SampledFairBinomial">previously observed</a> distribution of fair coin outcome ratios, the use of this probability distribution can be seen in action. 
As the number of trials grows, the distribution appears naturally simply due to differences in the number of possible realizations.</p>

<p><a name="BiasedBinomial"></a></p>

<h3 id="biased-binomial-distributions">Biased Binomial Distributions</h3>

<p>In the case of a <strong>fair coin</strong>, using this path-based approach appears sensible. 
But what can we do in case of biased binomial experiments?</p>

<p>For a biased coin, the <a href="/statistics/2016/07/11/Probabilities.html">probabilities</a> for each of the possible outcomes need to be considered in calculating the number of possible ways in which an event can happen.</p>

<p>Fortunately there is an extension to the binomial coefficient which allows calculation of probabilities of events with any bias. This extension is known as the <strong>binomial distribution</strong> and it is defined as</p>

<script type="math/tex; mode=display">P( X = k.out.of.n) = \binom{n}{k} p^k(1-p)^{n-k}</script>

<p>This formula consists of:</p>

<ol>
  <li>the binomial coefficient \(\binom{n}{k}\): the number of ways of distributing exactly <code class="highlighter-rouge">k</code> successes in a sequence of <code class="highlighter-rouge">n</code> independent bernoulli trials</li>
  <li>\(p^k\): the probability of <code class="highlighter-rouge">k</code> successful trials where each success has an individual probability of <code class="highlighter-rouge">p</code></li>
  <li>\((1-p)^{n-k}\): the probability of having <code class="highlighter-rouge">n-k</code> unsuccessful trials</li>
</ol>

<p>Using this formula, the probabilities for different ratios can be obtained for any underlying bias p.</p>

<p>In <em>R</em> the probability of a success ratio for a binomial experiment of a certain size and a certain event probability can be obtained with <code class="highlighter-rouge">dbinom(k, n, prob)</code>.</p>

<p>The following example returns the probability of having two heads in 3 coin tosses with a fair coin:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">dbinom</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>## [1] 0.375
</code></pre>
</div>

<p>We can also use <code class="highlighter-rouge">dbinom()</code> to obtain a probability distribution for different success ratios:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="c1">#par(mfrow = c(3,1))
</span><span class="n">barplot</span><span class="p">(</span><span class="n">dbinom</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="o">:</span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">),</span><span class="w"> 
        </span><span class="n">names.arg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="o">:</span><span class="m">100</span><span class="p">)</span><span class="o">/</span><span class="m">100</span><span class="p">,</span><span class="w"> 
        </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"lightcoral"</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<p><img src="/media/coins-unnamed-chunk-6-1.png" alt="plot of chunk unnamed-chunk-6" /></p>

<p>Note that with <code class="highlighter-rouge">prob = 0.5</code> this distribution is identical to the normalized 100s row of the pascal triangle visualized in <a href="#BinomHist100">an earlier histogram</a>.</p>

<p>When changing the bias of the coin, the distribution shifts its center accordingly:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="c1">#par(mfrow = c(2,1))
</span><span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">50</span><span class="w">
</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="o">:</span><span class="n">n</span><span class="w">
</span><span class="n">barplot</span><span class="p">(</span><span class="n">dbinom</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.7</span><span class="p">),</span><span class="w"> 
        </span><span class="n">names.arg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="o">/</span><span class="n">n</span><span class="p">,</span><span class="w"> 
        </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"lightcoral"</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<p><img src="/media/coins-unnamed-chunk-7-1.png" alt="plot of chunk unnamed-chunk-7" /></p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">barplot</span><span class="p">(</span><span class="n">dbinom</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.3</span><span class="p">),</span><span class="w"> 
        </span><span class="n">names.arg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="o">/</span><span class="n">n</span><span class="p">,</span><span class="w"> 
        </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"lightcoral"</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<p><img src="/media/coins-unnamed-chunk-7-2.png" alt="plot of chunk unnamed-chunk-7" /></p>

<p>We can therefore assume that the sampling distribution of the mean for samples obtained with a biased coin will also have it’s center near the ratio that corresponds to the coin’s bias.</p>

<h4 id="biased-gold">Biased Gold</h4>

<p>Let us now take a look at the distribution of means we get from performing multiple sets of coin flips with our gold coin.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">BinomMeansGold</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">experiments</span><span class="p">,</span><span class="w"> </span><span class="n">coinTosses</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="c1"># function to collect the mean outcomes of multiple binomial experiments
</span><span class="w">  </span><span class="c1"># using an old gold coin
</span><span class="w">  </span><span class="c1">#
</span><span class="w">  </span><span class="c1"># Args:
</span><span class="w">  </span><span class="c1">#  experiments: number of experiments
</span><span class="w">  </span><span class="c1">#  coinTosses:  number of trials per experiment
</span><span class="w">  </span><span class="c1">#
</span><span class="w">  </span><span class="c1"># Returns:
</span><span class="w">  </span><span class="c1">#  means: mean outcomes of multiple binomial experiments
</span><span class="w">  </span><span class="n">means</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="kc">NA</span><span class="p">)</span><span class="w">   </span><span class="c1"># make a list to store the mean values
</span><span class="w">  </span><span class="nf">length</span><span class="p">(</span><span class="n">means</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">experiments</span><span class="w"> </span><span class="c1"># allocate memory to store the mean values
</span><span class="w">  
  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">experiments</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1"># for each experiment
</span><span class="w">    </span><span class="c1"># flip a gold coin multiple times and store the average number of 
</span><span class="w">    </span><span class="c1"># 1's in a list
</span><span class="w">    </span><span class="n">means</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">GoldCoinToss</span><span class="p">(</span><span class="n">coinTosses</span><span class="p">))</span><span class="w">
  </span><span class="p">}</span><span class="w">
  </span><span class="nf">return</span><span class="p">(</span><span class="n">means</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">

</span><span class="c1"># collect mean values of 10000 x 1000 coin flips with the old gold coin
# The Shape of the distribution dependents on number of experiments 
# and the width is dependent on the number of coing tosses per experiment.
</span><span class="n">goldMeans</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">BinomMeansGold</span><span class="p">(</span><span class="n">experiments</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10000</span><span class="p">,</span><span class="w"> </span><span class="n">coinTosses</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1000</span><span class="p">)</span><span class="w">

</span><span class="c1"># show histograms of the collected means
</span><span class="n">hist</span><span class="p">(</span><span class="n">goldMeans</span><span class="p">,</span><span class="w"> </span><span class="n">breaks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">50</span><span class="p">,</span><span class="w"> </span><span class="n">freq</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"gold"</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<p><img src="/media/coins-unnamed-chunk-8-1.png" alt="plot of chunk unnamed-chunk-8" /></p>

<p>This distribution of mean outcomes suggests that this gold coin is more likely to land on one side than the other with a bias of around 0.618.</p>

<p>Because of our knowledge about the shape of binomial probability distributions we might be fairly confident that this bias is close to the true bias of the coin. <br />
However, in real life it is sometimes not possible to repeat an experiment thousands of times in order to replicate the probability distribution of a random variable. 
In a future post I will write about some approaches which are used for making inferences even with relatively small sample sizes.</p>


  </div>

</article>



<br/>
<br/>


<div id="disqus_thread"></div>
<!-- Add Disqus comments (not comment count) -->
<script>
    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
     */
    /*
    var disqus_config = function () {
        this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    var disqus_shortname  = 'kuruga';
    var disqus_identifier = '/statistics/2016/07/11/coins.html';
    var disqus_title      = 'Coins';
    var disqus_url        = 'https://kuruga.github.io//statistics/2016/07/11/coins.html';
    //var disqus_developer = 1; // Comment out when the site is live
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>

<!-- Add Disqus comments (not comment count) -->
<script type="text/javascript">
    (function() {  // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');

        s.src = '//kuruga.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>
    Enable JavaScript to view externally hosted <a href="https://disqus.com/?ref_noscript" rel="nofollow">Disqus comments.</a>
</noscript>



      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Satisfying Constraints</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>Satisfying Constraints</li>
          <li><a href="mailto:"></a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/kuruga"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">kuruga</span></a>

          </li>
          

          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>A blog about information.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
